apiVersion: batch/v1
kind: Job
metadata:
  name: wandb-agent
spec:
  backoffLimit: 0
  template:
    spec:
      restartPolicy: Never
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: nvidia.com/gpu.product
                    operator: In
                    values: ["NVIDIA-A10"]
      containers:
        - name: sweep-agent
          image: pytorch/pytorch:2.1.0-cuda11.8-cudnn8-runtime
          workingDir: /workspace
          volumeMounts:
            - name: workspace
              mountPath: /workspace
          resources:
            limits:
              nvidia.com/gpu: 1
          env:
            - name: WANDB_API_KEY
              value: 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
            - name: WANDB_PROJECT
              value: dpo-training
            - name: WORLD_SIZE
              value: "1"
            - name: RANK
              value: "0"
            - name: LOCAL_RANK
              value: "0"
            - name: MASTER_ADDR
              value: "127.0.0.1"
            - name: MASTER_PORT
              value: "29500"
          command: ["/bin/bash","-lc"]
          args:
            - |
              set -euo pipefail
              cd /workspace/repo
              # optional: git clone/update here if needed
              python -m venv /workspace/.venv
              source /workspace/.venv/bin/activate
              python -m pip install -U pip
              python -m pip install -r requirements.txt 
              python -c "import torch, transformers; print(torch.__version__, transformers.__version__)"
              nvidia-smi
              python -m wandb agent lemn-lab/dpo-training/l5n97h21
          resources:
            requests:
              cpu: "8"
              memory: "32Gi"
              nvidia.com/gpu: "1"
            limits:
              cpu: "16"
              memory: "32Gi"
              nvidia.com/gpu: "1"

      volumes:
        - name: workspace
          persistentVolumeClaim:
            claimName: dpo-sweep-storage